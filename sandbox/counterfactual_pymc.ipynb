{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36ef51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_days = 7 * 7  # 8 weeks\n",
    "days = np.arange(n_days)\n",
    "\n",
    "# Weekend: days 6 and 7 of each week\n",
    "is_weekend = np.array([(d % 7 in [5, 6]) for d in days], dtype=int)\n",
    "\n",
    "# Variant B in last week\n",
    "is_variant_b = np.array([1 if d >= 6*7 else 0 for d in days], dtype=int)\n",
    "\n",
    "# Observations: fewer on weekends\n",
    "observations = np.where(is_weekend, \n",
    "                        np.random.poisson(100, size=n_days), \n",
    "                        np.random.poisson(500, size=n_days))\n",
    "\n",
    "# Conversion rates: 0.05 normally, 0.06 for variant B\n",
    "p = 0.05 + 0.01 * is_variant_b\n",
    "successes = np.random.binomial(observations, p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94f26322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [logit_conversion_baseline, logit_weekend_adjustment, logit_uplift_variant_b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be917fc907e4d15b9b40ccb2c3f614a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 0 seconds.\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "from scipy.special import logit\n",
    "\n",
    "# --- Controlled Sequential A/B Test ---\n",
    "\n",
    "# Baseline conversion rate (Baseline conversion rate for the reference group: Variant A on weekdays)\n",
    "assumed_base_rate = 0.05  # 5%\n",
    "base_rate_uncertainty_pp = 0.015\n",
    "\n",
    "base_logit_mu = logit(assumed_base_rate)\n",
    "\n",
    "base_logit_sigma = (\n",
    "    logit(assumed_base_rate + base_rate_uncertainty_pp) -\n",
    "    logit(assumed_base_rate - base_rate_uncertainty_pp)\n",
    ") / 4\n",
    "\n",
    "# Weekend effect: 50% of weekday conversion, range 25%‚Äì75%\n",
    "weekend_multiplier_mu = np.log(0.5)\n",
    "weekend_multiplier_sigma = (np.log(0.75) - np.log(0.25)) / 4\n",
    "\n",
    "# Variant B expected uplift: ¬±2.5 percentage points around 5%\n",
    "uplift_range_pp = 0.025\n",
    "\n",
    "uplift_logit_sigma = (\n",
    "    logit(assumed_base_rate + uplift_range_pp) -\n",
    "    logit(assumed_base_rate - uplift_range_pp)\n",
    ") / 4\n",
    "\n",
    "# --- Probabilistic Model ---\n",
    "\n",
    "with pm.Model() as conversion_rate_model:\n",
    "\n",
    "    # Baseline conversion (Variant A, weekday)\n",
    "    logit_conversion_baseline = pm.Normal(\n",
    "        \"logit_conversion_baseline\",\n",
    "        mu=base_logit_mu,\n",
    "        sigma=base_logit_sigma\n",
    "    )\n",
    "\n",
    "    # Weekend adjustment (log-scale reduction in conversion)\n",
    "    logit_weekend_adjustment = pm.Normal(\n",
    "        \"logit_weekend_adjustment\",\n",
    "        mu=weekend_multiplier_mu,\n",
    "        sigma=weekend_multiplier_sigma\n",
    "    )\n",
    "\n",
    "    # Uplift from Variant B vs Variant A (in log-odds)\n",
    "    logit_uplift_variant_b = pm.Normal(\n",
    "        \"logit_uplift_variant_b\",\n",
    "        mu=0,\n",
    "        sigma=uplift_logit_sigma\n",
    "    )\n",
    "\n",
    "    # Linear predictor\n",
    "    logit_conversion = (\n",
    "        logit_conversion_baseline\n",
    "        + logit_weekend_adjustment * is_weekend\n",
    "        + logit_uplift_variant_b * is_variant_b\n",
    "    )\n",
    "\n",
    "    conversion_rate = pm.math.sigmoid(logit_conversion)\n",
    "\n",
    "    # Observed conversion data\n",
    "    observed_conversions = pm.Binomial(\n",
    "        \"observed_conversions\",\n",
    "        n=observations,\n",
    "        p=conversion_rate,\n",
    "        observed=successes\n",
    "    )\n",
    "\n",
    "    # Inference\n",
    "    trace = pm.sample(1000, tune=1000, target_accept=0.95)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33cc0eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logit_conversion_a_weekday</th>\n",
       "      <td>-3.019</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-3.154</td>\n",
       "      <td>-2.884</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2793.0</td>\n",
       "      <td>2946.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit_weekend_conversion_adjustment</th>\n",
       "      <td>-0.651</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-1.101</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2759.0</td>\n",
       "      <td>2273.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logit_uplift_variant_b</th>\n",
       "      <td>0.236</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2645.0</td>\n",
       "      <td>2769.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      mean     sd  hdi_3%  hdi_97%  mcse_mean  \\\n",
       "logit_conversion_a_weekday          -3.019  0.072  -3.154   -2.884      0.001   \n",
       "logit_weekend_conversion_adjustment -0.651  0.233  -1.101   -0.226      0.004   \n",
       "logit_uplift_variant_b               0.236  0.113   0.027    0.452      0.002   \n",
       "\n",
       "                                     mcse_sd  ess_bulk  ess_tail  r_hat  \n",
       "logit_conversion_a_weekday             0.001    2793.0    2946.0    1.0  \n",
       "logit_weekend_conversion_adjustment    0.004    2759.0    2273.0    1.0  \n",
       "logit_uplift_variant_b                 0.002    2645.0    2769.0    1.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.summary(trace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff96dbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  \\\n",
      "logit_conversion_baseline -2.908  0.035  -2.974   -2.843      0.001    0.001   \n",
      "logit_weekend_adjustment  -0.227  0.124  -0.475   -0.012      0.002    0.002   \n",
      "logit_uplift_variant_b     0.153  0.085  -0.007    0.309      0.001    0.001   \n",
      "\n",
      "                           ess_bulk  ess_tail  r_hat  \n",
      "logit_conversion_baseline    2831.0    2475.0    1.0  \n",
      "logit_weekend_adjustment     3402.0    2675.0    1.0  \n",
      "logit_uplift_variant_b       3407.0    2746.0    1.0  \n",
      "\n",
      "üìä Base conversion rate (Variant A weekday): 0.05%\n",
      "üìà Conversion rate with Variant B: 0.06%\n",
      "üîº Uplift from Variant B: 0.82 pp (95% HDI: [-0.09741036  1.73560889])\n",
      "‚úÖ Probability that Variant B is better than A: 96.2%\n",
      "‚ö†Ô∏è  Expected regret (if choosing Variant B): 0.01 pp\n",
      "   95% HDI for regret: [0.         0.09741036]\n"
     ]
    }
   ],
   "source": [
    "import arviz as az\n",
    "from scipy.special import expit\n",
    "import numpy as np\n",
    "\n",
    "# Summary from the trace with new variable names\n",
    "summary = az.summary(trace, var_names=[\n",
    "    \"logit_conversion_baseline\",\n",
    "    \"logit_weekend_adjustment\",\n",
    "    \"logit_uplift_variant_b\"\n",
    "])\n",
    "print(summary)\n",
    "\n",
    "# Extract samples\n",
    "logit_base = trace.posterior[\"logit_conversion_baseline\"].values.flatten()\n",
    "logit_uplift = trace.posterior[\"logit_uplift_variant_b\"].values.flatten()\n",
    "\n",
    "\n",
    "# Convert to probabilities\n",
    "p_base = expit(logit_base)\n",
    "p_b = expit(logit_base + logit_uplift)\n",
    "p_weekend = expit(logit_base + logit_weekend)\n",
    "\n",
    "# Percentage point differences\n",
    "pp_lift = (p_b - p_base) * 100\n",
    "\n",
    "\n",
    "# Interpretation prints\n",
    "print(f\"\\nüìä Base conversion rate (Variant A weekday): {p_base.mean():.2f}%\")\n",
    "print(f\"üìà Conversion rate with Variant B: {p_b.mean():.2f}%\")\n",
    "print(f\"üîº Uplift from Variant B: {pp_lift.mean():.2f} pp (95% HDI: {np.percentile(pp_lift, [2.5, 97.5])})\")\n",
    "\n",
    "# Probability that B is better than A\n",
    "prob_b_better = np.mean(p_b > p_base)\n",
    "print(f\"‚úÖ Probability that Variant B is better than A: {prob_b_better:.1%}\")\n",
    "\n",
    "# Regret if choosing Variant B and it's actually worse\n",
    "regret_if_choosing_b = np.where(p_base > p_b, p_base - p_b, 0) * 100  # in percentage points\n",
    "print(f\"‚ö†Ô∏è  Expected regret (if choosing Variant B): {regret_if_choosing_b.mean():.2f} pp\")\n",
    "print(f\"   95% HDI for regret: {np.percentile(regret_if_choosing_b, [2.5, 97.5])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b7415b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lift: 0.0222 (2.22 percentage points)\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "intercept = -2.995\n",
    "beta_variant_b = 0.406\n",
    "\n",
    "p_base = expit(intercept)\n",
    "p_b = expit(intercept + beta_variant_b)\n",
    "lift = p_b - p_base\n",
    "\n",
    "print(f\"Lift: {lift:.4f} ({lift * 100:.2f} percentage points)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-toolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
