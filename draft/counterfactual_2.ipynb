{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47bf9c88",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (3501785250.py, line 53)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mstart_date=\"2025-01-01\",\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def simulate_binomial_conversion_data(\n",
    "    start_date=\"2025-01-01\",\n",
    "    train_days=180,\n",
    "    test_days=14,\n",
    "    base_rate=0.05,\n",
    "    rate_increase=0.01,\n",
    "    trend_slope=0.0001,\n",
    "    seasonality_amplitude=0.005,\n",
    "    noise_sd=0.01,\n",
    "    holiday_dates=None,\n",
    "    base_trials=1000,\n",
    "    weekend_trial_factor=0.4  # weekends get fewer trials\n",
    "):\n",
    "    total_days = train_days + test_days\n",
    "    dates = pd.date_range(start=start_date, periods=total_days)\n",
    "    data = []\n",
    "\n",
    "    for i, date in enumerate(dates):\n",
    "        day_of_week = date.weekday()\n",
    "        date_str = date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        trend = trend_slope * i\n",
    "        seasonality = seasonality_amplitude * np.sin(2 * np.pi * day_of_week / 7)\n",
    "        noise = np.random.normal(0, noise_sd)\n",
    "\n",
    "        # Weekend or holiday trial count adjustment\n",
    "        trial_multiplier = weekend_trial_factor if day_of_week >= 5 else 1.0\n",
    "        trial_multiplier = min(trial_multiplier, 0.5 if holiday_dates and date_str in holiday_dates else 1.0)\n",
    "        n_trials = int(base_trials * trial_multiplier)\n",
    "\n",
    "        # Conversion rate + variant effect\n",
    "        effective_base = base_rate + trend + seasonality + noise\n",
    "        variant_effect = rate_increase if i >= train_days else 0.0\n",
    "        final_rate = np.clip(effective_base + variant_effect, 0.0001, 0.9999)\n",
    "\n",
    "        conversions = np.random.binomial(n_trials, final_rate)\n",
    "\n",
    "        data.append({\n",
    "            \"date\": date,\n",
    "            \"conversions\": conversions,\n",
    "            \"n_trials\": n_trials,\n",
    "            \"is_variant_b\": int(i >= train_days),\n",
    "            \"day_of_week\": day_of_week\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    dummies = pd.get_dummies(df[\"day_of_week\"], prefix=\"dow\", drop_first=True)\n",
    "    return pd.concat([df, dummies], axis=1)\n",
    "(\n",
    "    start_date=\"2025-01-01\",\n",
    "    train_days=180,\n",
    "    test_days=14,\n",
    "    base_rate=0.05,\n",
    "    rate_increase=0.01,\n",
    "    trend_slope=0.0001,\n",
    "    seasonality_amplitude=0.005,\n",
    "    noise_sd=0.01,\n",
    "    holiday_dates=None,\n",
    "    base_trials=1000,\n",
    "    weekend_trial_factor=0.4  # weekends get fewer trials\n",
    "):\n",
    "    total_days = train_days + test_days\n",
    "    dates = pd.date_range(start=start_date, periods=total_days)\n",
    "    data = []\n",
    "\n",
    "    for i, date in enumerate(dates):\n",
    "        day_of_week = date.weekday()\n",
    "        date_str = date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        trend = trend_slope * i\n",
    "        seasonality = seasonality_amplitude * np.sin(2 * np.pi * day_of_week / 7)\n",
    "        noise = np.random.normal(0, noise_sd)\n",
    "\n",
    "        # Weekend or holiday trial count adjustment\n",
    "        trial_multiplier = weekend_trial_factor if day_of_week >= 5 else 1.0\n",
    "        trial_multiplier = min(trial_multiplier, 0.5 if holiday_dates and date_str in holiday_dates else 1.0)\n",
    "        n_trials = int(base_trials * trial_multiplier)\n",
    "\n",
    "        # Conversion rate + variant effect\n",
    "        effective_base = base_rate + trend + seasonality + noise\n",
    "        variant_effect = rate_increase if i >= train_days else 0.0\n",
    "        final_rate = np.clip(effective_base + variant_effect, 0.0001, 0.9999)\n",
    "\n",
    "        conversions = np.random.binomial(n_trials, final_rate)\n",
    "\n",
    "        data.append({\n",
    "            \"date\": date,\n",
    "            \"conversions\": conversions,\n",
    "            \"n_trials\": n_trials,\n",
    "            \"is_variant_b\": int(i >= train_days),\n",
    "            \"day_of_week\": day_of_week\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    dummies = pd.get_dummies(df[\"day_of_week\"], prefix=\"dow\", drop_first=True)\n",
    "    return pd.concat([df, dummies], axis=1)\n",
    "(\n",
    "    start_date=\"2025-01-01\",\n",
    "    train_days=180,\n",
    "    test_days=14,\n",
    "    base_rate=0.05,\n",
    "    rate_increase=0.01,\n",
    "    trend_slope=0.0001,\n",
    "    seasonality_amplitude=0.005,\n",
    "    noise_sd=0.01,\n",
    "    holiday_dates=None,\n",
    "    base_trials=1000,\n",
    "    weekend_trial_factor=0.4  # weekends get fewer trials\n",
    "):\n",
    "    total_days = train_days + test_days\n",
    "    dates = pd.date_range(start=start_date, periods=total_days)\n",
    "    data = []\n",
    "\n",
    "    for i, date in enumerate(dates):\n",
    "        day_of_week = date.weekday()\n",
    "        date_str = date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        trend = trend_slope * i\n",
    "        seasonality = seasonality_amplitude * np.sin(2 * np.pi * day_of_week / 7)\n",
    "        noise = np.random.normal(0, noise_sd)\n",
    "\n",
    "        # Weekend or holiday trial count adjustment\n",
    "        trial_multiplier = weekend_trial_factor if day_of_week >= 5 else 1.0\n",
    "        trial_multiplier = min(trial_multiplier, 0.5 if holiday_dates and date_str in holiday_dates else 1.0)\n",
    "        n_trials = int(base_trials * trial_multiplier)\n",
    "\n",
    "        # Conversion rate + variant effect\n",
    "        effective_base = base_rate + trend + seasonality + noise\n",
    "        variant_effect = rate_increase if i >= train_days else 0.0\n",
    "        final_rate = np.clip(effective_base + variant_effect, 0.0001, 0.9999)\n",
    "\n",
    "        conversions = np.random.binomial(n_trials, final_rate)\n",
    "\n",
    "        data.append({\n",
    "            \"date\": date,\n",
    "            \"conversions\": conversions,\n",
    "            \"n_trials\": n_trials,\n",
    "            \"is_variant_b\": int(i >= train_days),\n",
    "            \"day_of_week\": day_of_week\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    dummies = pd.get_dummies(df[\"day_of_week\"], prefix=\"dow\", drop_first=True)\n",
    "    return pd.concat([df, dummies], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb3f493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def simulate_binomial_conversion_data(\n",
    "    start_date=\"2025-01-01\",\n",
    "    train_days=180,\n",
    "    test_days=14,\n",
    "    base_rate=0.05,\n",
    "    rate_increase=0.01,\n",
    "    trend_slope=0.0001,\n",
    "    seasonality_amplitude=0.005,\n",
    "    noise_sd=0.01,\n",
    "    holiday_dates=None,\n",
    "    base_trials=1000,\n",
    "    weekend_trial_factor=0.4  # weekends get fewer trials\n",
    "):\n",
    "    total_days = train_days + test_days\n",
    "    dates = pd.date_range(start=start_date, periods=total_days)\n",
    "    data = []\n",
    "\n",
    "    for i, date in enumerate(dates):\n",
    "        day_of_week = date.weekday()\n",
    "        date_str = date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        trend = trend_slope * i\n",
    "        seasonality = seasonality_amplitude * np.sin(2 * np.pi * day_of_week / 7)\n",
    "        noise = np.random.normal(0, noise_sd)\n",
    "\n",
    "        # Weekend or holiday trial count adjustment\n",
    "        trial_multiplier = weekend_trial_factor if day_of_week >= 5 else 1.0\n",
    "        trial_multiplier = min(trial_multiplier, 0.5 if holiday_dates and date_str in holiday_dates else 1.0)\n",
    "        n_trials = int(base_trials * trial_multiplier)\n",
    "\n",
    "        # Conversion rate + variant effect\n",
    "        effective_base = base_rate + trend + seasonality + noise\n",
    "        variant_effect = rate_increase if i >= train_days else 0.0\n",
    "        final_rate = np.clip(effective_base + variant_effect, 0.0001, 0.9999)\n",
    "\n",
    "        conversions = np.random.binomial(n_trials, final_rate)\n",
    "\n",
    "        data.append({\n",
    "            \"date\": date,\n",
    "            \"conversions\": conversions,\n",
    "            \"n_trials\": n_trials,\n",
    "            \"is_variant_b\": int(i >= train_days),\n",
    "            \"day_of_week\": day_of_week\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    dummies = pd.get_dummies(df[\"day_of_week\"], prefix=\"dow\", drop_first=True)\n",
    "    return pd.concat([df, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f94988e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = simulate_binomial_conversion_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33985acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from orbit.models import DLT\n",
    "\n",
    "def train_dlt_with_log_exposure(df):\n",
    "    regressors = [col for col in df.columns if col.startswith(\"dow_\")] + [\"is_variant_b\", \"log_trials\"]\n",
    "\n",
    "    model = DLT(\n",
    "        date_col=\"date\",\n",
    "        response_col=\"conversion_rate\",\n",
    "        regressor_col=regressors,\n",
    "        estimator=\"stan-mcmc\",\n",
    "        seasonality=None\n",
    "    )\n",
    "    model.fit(df=df)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89a38af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"conversion_rate\"] = df[\"conversions\"] / df[\"n_trials\"]\n",
    "df[\"log_trials\"] = np.log(df[\"n_trials\"] + 1e-8).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a46c655e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mtrain_dlt_with_log_exposure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mtrain_dlt_with_log_exposure\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m      4\u001b[39m regressors = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df.columns \u001b[38;5;28;01mif\u001b[39;00m col.startswith(\u001b[33m\"\u001b[39m\u001b[33mdow_\u001b[39m\u001b[33m\"\u001b[39m)] + [\u001b[33m\"\u001b[39m\u001b[33mis_variant_b\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlog_trials\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      6\u001b[39m model = DLT(\n\u001b[32m      7\u001b[39m     date_col=\u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     response_col=\u001b[33m\"\u001b[39m\u001b[33mconversion_rate\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     seasonality=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     12\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/bayesian-toolbox/lib/python3.12/site-packages/orbit/forecaster/full_bayes.py:36\u001b[39m, in \u001b[36mFullBayesianForecaster.fit\u001b[39m\u001b[34m(self, df, point_method, keep_samples, sampling_temperature, **kwargs)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     30\u001b[39m     df,\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m     **kwargs,\n\u001b[32m     35\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_temperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampling_temperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mself\u001b[39m._point_method = point_method\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m point_method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/bayesian-toolbox/lib/python3.12/site-packages/orbit/forecaster/forecaster.py:149\u001b[39m, in \u001b[36mForecaster.fit\u001b[39m\u001b[34m(self, df, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28mself\u001b[39m._set_training_meta(df)\n\u001b[32m    148\u001b[39m \u001b[38;5;66;03m# customize module\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_dynamic_attributes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_meta\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_training_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# based on the model and df, set training input\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;28mself\u001b[39m.set_training_data_input()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/bayesian-toolbox/lib/python3.12/site-packages/orbit/template/dlt.py:553\u001b[39m, in \u001b[36mDLTModel.set_dynamic_attributes\u001b[39m\u001b[34m(self, df, training_meta)\u001b[39m\n\u001b[32m    551\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_training_df_with_regression(df)\n\u001b[32m    552\u001b[39m \u001b[38;5;66;03m# depends on num_of_observations\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_regressor_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_meta\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTrainingMetaKeys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mNUM_OF_OBS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.global_trend_sigma_prior \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    556\u001b[39m     \u001b[38;5;28mself\u001b[39m.global_trend_sigma_prior = training_meta[\n\u001b[32m    557\u001b[39m         TrainingMetaKeys.RESPONSE_SD.value\n\u001b[32m    558\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/bayesian-toolbox/lib/python3.12/site-packages/orbit/template/dlt.py:537\u001b[39m, in \u001b[36mDLTModel._set_regressor_matrix\u001b[39m\u001b[34m(self, df, num_of_observations)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_of_regular_regressors > \u001b[32m0\u001b[39m:\n\u001b[32m    534\u001b[39m     \u001b[38;5;28mself\u001b[39m.regular_regressor_matrix = df.filter(\n\u001b[32m    535\u001b[39m         items=\u001b[38;5;28mself\u001b[39m.regular_regressor_col,\n\u001b[32m    536\u001b[39m     ).values\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.all(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mregular_regressor_matrix\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[32m    538\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ModelException(\n\u001b[32m    539\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mInvalid regressors values. They must be all not missing and finite.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    540\u001b[39m         )\n",
      "\u001b[31mTypeError\u001b[39m: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "model = train_dlt_with_log_exposure(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b664b8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m samples = \u001b[43mmodel\u001b[49m.get_posterior_samples()\n\u001b[32m      2\u001b[39m effect_samples = samples[\u001b[33m\"\u001b[39m\u001b[33mbeta\u001b[39m\u001b[33m\"\u001b[39m][:, regressors.index(\u001b[33m\"\u001b[39m\u001b[33mis_variant_b\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEstimated uplift:\u001b[39m\u001b[33m\"\u001b[39m, np.mean(effect_samples))\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "samples = model.get_posterior_samples()\n",
    "effect_samples = samples[\"beta\"][:, regressors.index(\"is_variant_b\")]\n",
    "\n",
    "print(\"Estimated uplift:\", np.mean(effect_samples))\n",
    "print(\"95% CI:\", np.percentile(effect_samples, [2.5, 97.5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927c7a6b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-toolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
